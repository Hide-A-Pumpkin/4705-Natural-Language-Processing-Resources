{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2BVH_JD9WiA"
      },
      "source": [
        "Below we will try and fit a Logisitc Regression Model step by step for the XOR problem.\n",
        "Fill in the code where there is a `_FILL_` specified. For this model, we have $x_1$ and $x_2$ are either 0/1 each and $y = x_1 + x_2 - 2x_1x_2$. Notice that this is True (1) if $x_1 = 1$ and $x_2 = 0$ OR $x_1 = 0$ and $x_2 = 1$; $y$ is zero otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wiFGf-9H9X3d"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "# Don't fill this in\n",
        "_FILL_ = '_FILL_'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1TRwUp469X-r"
      },
      "outputs": [],
      "source": [
        "x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y_data = [[0], [1], [1], [0]]\n",
        "x_data = torch.Tensor(x_data)\n",
        "y_data = torch.Tensor(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2FJM6ckGBRz_"
      },
      "outputs": [],
      "source": [
        "# Define each tensor to be 1x1 and have them require a gradient for tracking; these are parameters\n",
        "alpha = torch.randn(1, requires_grad=True)\n",
        "beta_1 = torch.randn(1, requires_grad=True)\n",
        "beta_2 = torch.randn(1, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BToqdBCr9YBI",
        "outputId": "2d08fd64-23e5-4013-c407-14a5f9b1e4ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Loss: 0.7696713805198669 Accuracy: 0.5\n",
            "Epoch: 1\n",
            "Loss: 0.7687812447547913 Accuracy: 0.5\n",
            "Epoch: 2\n",
            "Loss: 0.7679104208946228 Accuracy: 0.5\n",
            "Epoch: 3\n",
            "Loss: 0.7670583724975586 Accuracy: 0.5\n",
            "Epoch: 4\n",
            "Loss: 0.7662245631217957 Accuracy: 0.5\n",
            "Epoch: 5\n",
            "Loss: 0.7654088735580444 Accuracy: 0.5\n",
            "Epoch: 6\n",
            "Loss: 0.7646105289459229 Accuracy: 0.5\n",
            "Epoch: 7\n",
            "Loss: 0.7638294100761414 Accuracy: 0.5\n",
            "Epoch: 8\n",
            "Loss: 0.763064980506897 Accuracy: 0.5\n",
            "Epoch: 9\n",
            "Loss: 0.7623169422149658 Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "lr = 0.01\n",
        "\n",
        "for epoch in range(10):\n",
        "  for x, y in zip(x_data, y_data):\n",
        "\n",
        "    # Have z be beta_2*x[0] + beta_1*x[1] + alpha\n",
        "    z = beta_2*x[0] + beta_1*x[1] + alpha\n",
        "\n",
        "    # Push z through a nn.Sigmoid layer to get the p(y=1)\n",
        "    a = torch.sigmoid(z)\n",
        "\n",
        "    # Write the loss manually between y and a\n",
        "    loss = -y*torch.log(a) - (1-y)*torch.log(1-a)\n",
        "\n",
        "    # Get the loss gradients; the gradients with respect to alpha, beta_1, beta_2\n",
        "    loss.backward()\n",
        "    \n",
        "\n",
        "    # Manually update the gradients\n",
        "    # What we do below is wrapped within this clause because weights have required_grad=True but we don't need to track this in autograd\n",
        "    with torch.no_grad():\n",
        "        # Do an update for each parameter\n",
        "        alpha -= lr * alpha.grad\n",
        "        beta_1 -= lr * beta_1.grad\n",
        "        beta_2 -= lr * beta_2.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        alpha.grad.zero_()\n",
        "        beta_1.grad.zero_()\n",
        "        beta_2.grad.zero_()\n",
        "\n",
        "  # Manually get the accuracy of the model after each epoch\n",
        "  with torch.no_grad():\n",
        "    print(f'Epoch: {epoch}')\n",
        "    y_pred = []\n",
        "    loss = 0.0\n",
        "\n",
        "    for x, y in zip(x_data, y_data):\n",
        "      # Get z\n",
        "      z = beta_2*x[0] + beta_1*x[1] + alpha\n",
        "\n",
        "      # Get a\n",
        "      a = torch.sigmoid(z)\n",
        "\n",
        "      # Get the loss\n",
        "      loss += -y*torch.log(a) - (1-y)*torch.log(1-a)\n",
        "\n",
        "      # Get the prediction given a\n",
        "      y_pred.append(1 if a > 0.5 else 0)\n",
        "\n",
        "    # Get the current accuracy over 4 points; make this a tensor\n",
        "    y_pred = torch.tensor(y_pred)\n",
        "\n",
        "    accuracy = (y_pred == y_data).float().mean()\n",
        "    loss = loss / 4\n",
        "\n",
        "    # Print the accuracy and the loss\n",
        "    # You want the item in the tensor thats 1x1\n",
        "    print('Loss: {} Accuracy: {}'.format(loss.item(), accuracy.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iojtw_rFAjhY"
      },
      "source": [
        "Exercise 1: Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgdImVPpAm6d",
        "outputId": "9a3d2ea6-8f33-4fd7-adfe-b7b7c09ecf82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.5240, -0.7444,  0.5727]],\n",
              "\n",
              "        [[-0.3527, -0.6371, -0.1981]]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=torch.randn(2, 3).unsqueeze(dim=1)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yfuo7fAneJ"
      },
      "source": [
        "Exercise 2: Remove the extra dimension you just added to the previous tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goe1-DBRAnnj",
        "outputId": "499138aa-f429-474a-e8af-53e34add8b1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.5240, -0.7444,  0.5727],\n",
              "        [-0.3527, -0.6371, -0.1981]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x =x.squeeze()\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAhtAtk5Any4"
      },
      "source": [
        "Exercise 3: Create a random tensor of shape 5x3 in the interval [3, 7)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcFowEjAn8w",
        "outputId": "6b2553d5-b139-419d-d845-a8c535b303cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3.3034, 4.3474, 6.9959],\n",
              "        [3.1301, 4.1922, 4.2445],\n",
              "        [3.4870, 6.1628, 4.1539],\n",
              "        [4.0046, 3.6545, 4.2316],\n",
              "        [6.5788, 6.3570, 6.7518]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "3 + torch.rand(5, 3) * 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvNprVRlAoEC"
      },
      "source": [
        "Exercise 4: Create a tensor with values from a normal distribution (mean=0, std=1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Dgirc4kGAoKa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.4396,  0.7305,  1.2345],\n",
              "        [ 2.0732, -0.7741, -1.0739],\n",
              "        [-0.6972, -1.8511, -0.8051]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(3,3).normal_(mean=0, std=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1nIIGp8AoQL"
      },
      "source": [
        "exercise 5: Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCv5zbq3AoV-",
        "outputId": "9942ce9c-c763-49e0-93c2-b6baf7d81333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [1],\n",
              "        [2],\n",
              "        [4]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=torch.Tensor([1, 1, 1, 0, 1])\n",
        "torch.nonzero(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckErX5U1Aocz"
      },
      "source": [
        "Exercise 6: Create a random tensor of size (3,1) and then horizonally stack 4 copies together.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D3XYAnoAoig",
        "outputId": "2554e44d-f170-4b09-e966-1e25b54b4322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7343, 0.7343, 0.7343, 0.7343],\n",
              "        [0.1371, 0.1371, 0.1371, 0.1371],\n",
              "        [0.5051, 0.5051, 0.5051, 0.5051]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(3,1).expand(3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKV3ChJrAopD"
      },
      "source": [
        "Exercise 7: Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge6IErGdAovX",
        "outputId": "dd39067a-72d2-42e8-b955-7aa783e626ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.8256, 0.8774, 0.9409, 1.5316],\n",
              "         [0.4824, 0.5852, 0.4013, 1.0560],\n",
              "         [0.9193, 1.1430, 1.2075, 1.6282],\n",
              "         [1.0752, 1.3022, 1.2029, 1.9151]],\n",
              "\n",
              "        [[1.0178, 1.1421, 0.8326, 1.3754],\n",
              "         [0.5466, 0.8347, 0.3251, 1.1396],\n",
              "         [0.3506, 0.4528, 0.2895, 0.5627],\n",
              "         [1.2862, 1.8336, 1.3080, 1.9938]],\n",
              "\n",
              "        [[1.8646, 1.5553, 1.4375, 1.2376],\n",
              "         [1.9361, 1.8066, 1.7534, 1.3161],\n",
              "         [2.1781, 2.0065, 1.8016, 1.0613],\n",
              "         [1.7194, 1.3998, 1.3294, 1.2011]]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.rand(3,4,5)\n",
        "b = torch.rand(3,5,4)\n",
        "torch.bmm(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVI_LI_PA_2e"
      },
      "source": [
        "Exercise 8: Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpLgovtyBAA6",
        "outputId": "5ec0cb93-d699-46af-dbfa-e76e104da8ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1.7260, 1.3707, 1.2195, 1.5173],\n",
              "         [1.7599, 1.8178, 2.1290, 2.0782],\n",
              "         [1.7229, 1.5337, 2.1185, 1.9211],\n",
              "         [1.1690, 1.3057, 1.5000, 1.4344]],\n",
              "\n",
              "        [[1.2274, 0.6852, 1.4323, 1.1770],\n",
              "         [0.7564, 1.0317, 1.1052, 1.0394],\n",
              "         [1.0998, 1.3043, 1.1831, 1.4294],\n",
              "         [1.5357, 1.1266, 1.7714, 1.5891]],\n",
              "\n",
              "        [[1.2535, 1.3614, 1.6904, 1.6466],\n",
              "         [1.5170, 1.6165, 1.9225, 1.9392],\n",
              "         [0.7325, 1.1157, 1.2611, 1.2070],\n",
              "         [0.9363, 1.3898, 1.2894, 1.3576]]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.rand(3,4,5)\n",
        "b = torch.rand(5,4)\n",
        "\n",
        "torch.bmm(a, b.unsqueeze(dim=0).expand(a.size(0),*b.size()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW6NxQIeBAJA"
      },
      "source": [
        "Exercise 9: Create a 1x1 random tensor and get the value inside of this tensor as a scalar. No tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_OFj9hEBAPO",
        "outputId": "32349d97-a959-419a-aa3d-1da4e29e65ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6220725178718567"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(1).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_zAwiqrBAVd"
      },
      "source": [
        "Exercise 10: Create a 2x1 tensor and have it require a gradient. Have $x$, this tensor, hold [-2, 1]. Set $y=x_1^2 + x_2^2$ and get the gradient of y with respect to $x_1$ and then $x_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z98hDPfEBAcv",
        "outputId": "2c683c02-4f3b-4ddd-d820-d986b68d2fc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-4.,  2.])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "x = torch.tensor([-2.0,1.0],requires_grad=True)\n",
        "y = x[0]**2+x[1]**2\n",
        "y.backward()\n",
        "\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGfmkpF3BAjy"
      },
      "source": [
        "Exercise 11: Check if cuda is available (it shuld be if in the Runtime setting for colab you choose the GPU). If it is, move $x$ above to a CUDA device. Create a new tensor of the same shape as $x$ and put it on the cpu. Try and add these tensors. What happens. How do you fix this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "2M_Suz2XBAsX",
        "outputId": "ab952026-83ce-4a6c-a6db-59d4cd4e4081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda is not available!\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    print(\"x is now on:\", x.device)\n",
        "    \n",
        "    y = torch.tensor([1,1]).to('cpu')\n",
        "    print(\"y is on:\", y.device)\n",
        "    \n",
        "    try:\n",
        "        z = x + y\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        \n",
        "    # Solution: Move one of the tensors to the same device \n",
        "    y = y.cuda()\n",
        "    z = x + y\n",
        "    print(z)\n",
        "else:\n",
        "    print('cuda is not available!')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
