{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21016.0 17324.0\n"
     ]
    }
   ],
   "source": [
    "# problem 6\n",
    "\n",
    "import torch\n",
    "\n",
    "# Define the tensors and set requires_grad=True to enable gradient computation\n",
    "u1 = torch.tensor(3.0, requires_grad=True)\n",
    "u2 = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "# Define the equations\n",
    "u3 = u1 * u2\n",
    "u4 = u1 + u2\n",
    "u5 = 2 * u3 * u4\n",
    "L = (u5 - u1 - u2 - u3 - u4) ** 2\n",
    "\n",
    "# Compute the gradients\n",
    "L.backward()\n",
    "\n",
    "# Extract the gradients for u1 and u2\n",
    "grad_u1 = u1.grad.item()\n",
    "grad_u2 = u2.grad.item()\n",
    "\n",
    "print(grad_u1, grad_u2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/10000], Loss: 0.6929\n",
      "Epoch [2000/10000], Loss: 0.6912\n",
      "Epoch [3000/10000], Loss: 0.6819\n",
      "Epoch [4000/10000], Loss: 0.6241\n",
      "Epoch [5000/10000], Loss: 0.5011\n",
      "Epoch [6000/10000], Loss: 0.2430\n",
      "Epoch [7000/10000], Loss: 0.0910\n",
      "Epoch [8000/10000], Loss: 0.0507\n",
      "Epoch [9000/10000], Loss: 0.0344\n",
      "Epoch [10000/10000], Loss: 0.0258\n",
      "Accuracy: 1.0000\n",
      "Learned weights and biases:\n",
      "layer1.weight tensor([[6.3122, 6.3349],\n",
      "        [4.2893, 4.2930]])\n",
      "layer1.bias tensor([-2.7189, -6.5576])\n",
      "layer2.weight tensor([[ 8.9446, -9.5765]])\n",
      "layer2.bias tensor([-4.0780])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the XOR dataset\n",
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "Y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "# Define the neural network model\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 1)\n",
    "        self.layer2 = nn.Linear(1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.layer1(x))\n",
    "        x = self.sigmoid(self.layer2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = XORModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 1000 epochs\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    accuracy = y_predicted_cls.eq(Y).sum() / float(Y.shape[0])\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print the learned weights and biases\n",
    "print(\"Learned weights and biases:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.27808853e-01 6.65275539e-06]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[1;32m     31\u001b[0m     output \u001b[39m=\u001b[39m xor_neural_network(inputs[i], beta1, alpha1, beta2, alpha2)\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mabs(output \u001b[39m-\u001b[39m outputs[i]) \u001b[39m>\u001b[39m \u001b[39m0.1\u001b[39m:\n\u001b[1;32m     33\u001b[0m         correct \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def xor_neural_network(x, beta1, alpha1, beta2, alpha2):\n",
    "    z1 = np.dot(beta1, x) + alpha1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(beta2, a1) + alpha2\n",
    "    a2 = sigmoid(z2)\n",
    "    print(a2)\n",
    "    return a2\n",
    "\n",
    "# Define the XOR inputs and outputs\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Initial weights and biases\n",
    "beta1 = np.array([[1, 1], [1, 1]])\n",
    "alpha1 = np.array([0, -1])\n",
    "beta2 = np.array([1, 1])  # This will be adjusted in the search\n",
    "alpha2 = np.array([0, 0])  # This will be adjusted in the search\n",
    "\n",
    "# Brute-force search for gamma and nu\n",
    "for gamma in np.linspace(-10, 10, 1000):\n",
    "    for nu in np.linspace(-10, 10, 1000):\n",
    "        beta2[1] = beta2[0] + gamma\n",
    "        alpha2[1] = alpha2[0] + nu\n",
    "        correct = True\n",
    "        for i in range(4):\n",
    "            output = xor_neural_network(inputs[i], beta1, alpha1, beta2, alpha2)\n",
    "            if np.abs(output - outputs[i]) > 0.1:\n",
    "                correct = False\n",
    "                break\n",
    "        if correct:\n",
    "            print(\"Found values that work:\")\n",
    "            print(\"Gamma:\", gamma)\n",
    "            print(\"Nu:\", nu)\n",
    "            break\n",
    "    if correct:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
