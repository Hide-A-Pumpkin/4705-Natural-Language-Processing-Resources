{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a5460e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "WORDTAG = 'WORDTAG'\n",
    "GRAM1 = '1-GRAM'\n",
    "GRAM2 = '2-GRAM'\n",
    "GRAM3 = '3-GRAM'\n",
    "RARE = '_RARE_'\n",
    "RARE_THRESHOLD = 5\n",
    "# A I-LOC might be followed by B-LOC if a new location follow one immediately after another one                                                                                                              \n",
    "# There are 9 tags to consider                                                                                                                                                                               \n",
    "TAGS = [\n",
    "    'I-PER',\n",
    "    'I-ORG',\n",
    "    'I-LOC',\n",
    "    'I-MISC',\n",
    "    'B-PER',\n",
    "    'B-ORG',\n",
    "    'B-LOC',\n",
    "    'B-MISC',\n",
    "    'O'\n",
    "]\n",
    "# The start and stop symbols                                                                                                                                                                                 \n",
    "START = '*'\n",
    "STOP = 'STOP'\n",
    "\n",
    "FILL_IN = '_FILL_IN_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9047be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_counts[(u, v, w)] = count(u, v, w)\n",
    "# q_counts[[u, v]] = count(u, v)\n",
    "# e_counts[(u, x)] = count(u, x)\n",
    "def get_q_e_counts(counts_file_name = 'ner.counts'):\n",
    "    f = open(counts_file_name)\n",
    "\n",
    "    q_counts = defaultdict(int)\n",
    "    e_counts = defaultdict(int)\n",
    "\n",
    "    FILL_IN\n",
    "\n",
    "    return q_counts, e_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "397c5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transforms the data into one involving the rare words                                                                                                                                                 \n",
    "# We then run the count_freqs.py utility to get the new counts across the corpus                                                                                                                             \n",
    "def transform_data(e_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "    Output:\n",
    "        Nothing; write to g\n",
    "    \"\"\"\n",
    "    f = open('ner_train.dat', 'r')\n",
    "    g = open('ner_train_rare.dat', 'w')\n",
    "\n",
    "    FILL_IN\n",
    "\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2a0462e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities e(x_t | y_t)                                                                                                                                                                   \n",
    "def get_emission(y, x, e_counts, x_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y: A tag\n",
    "        x: A word\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "        x_counts: A dictionary with counts(x)\n",
    "    Output:\n",
    "        The probabilty e(x|y) or e(RARE|y) is x is rare\n",
    "        This is vartheta(x | y) in the lecture\n",
    "    \"\"\"\n",
    "    # If a rare word, return e(RARE | y)\n",
    "    FILL_IN\n",
    "    # Otherwise, return e(x | y)                                                                                                                                                                             \n",
    "    FILL_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "36abd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not that for the baseline decoder we don't need Dynamic Programming\n",
    "# We have max_{y1, ..., YT} = max_{y1}(e(x1|y1))...max_{yT}(e(xT|yT))\n",
    "def baseline_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x, y, log(e(x|y))\" where y is the optimal tag for x\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.baseline_predictions', 'w')\n",
    "\n",
    "    _, e_counts = get_q_e(counts_file_name)\n",
    "    \n",
    "    # Get the counts per word; this is used to get the rare words                                                                                                                                            \n",
    "    # What words need to be replaced with a rare word?\n",
    "    # Note that we do here is take all counts of (u, x) for all u to get the count for x\n",
    "    x_counts = defaultdict(int)\n",
    "    FILL_IN\n",
    "\n",
    "    for l in f:\n",
    "        if not l or l == '\\n':\n",
    "            FILL_IN\n",
    "        else:\n",
    "            FILL_IN\n",
    "            g.write('{} {} {}\\n'.format(x, y_best, np.log(p_best)))\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e9014561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities p(y_t | y_{t-1}, y_{t-2})                                                                                                                                                      \n",
    "def get_transition(y1, y2, y3, q_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y1: The tag two away from the output tag\n",
    "        y2: The tag right before the output tag\n",
    "        y3: The output tag\n",
    "        q_counts: The counts we need for two or 3 tags beting seen together\n",
    "    Output:\n",
    "        q(w | v, u) which is theta(w | v, u) in the lecture\n",
    "    \"\"\"\n",
    "    if (y1, y2) not in q_counts:\n",
    "        FILL_IN\n",
    "    return FILL_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c2856a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x_t, y_t, log(pi(t, y_{t-1}, y_t))\" where y_t is the optimal tag for x_t\n",
    "        Note that {y_t} is the optimal sequence here, computed by Dynamic Programming\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.hmm_predictions', 'w')\n",
    "\n",
    "    FILL_IN\n",
    "\n",
    "    # Get the counts per word; this is used to identify                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "    FILL_IN\n",
    "\n",
    "    # Can use log probabilities here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "    # Reset all variables                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "    pi = defaultdict(float)\n",
    "    bp = defaultdict(str)\n",
    "    pi[(0, START, START)] = 1.0\n",
    "    T = 0\n",
    "    xT = []\n",
    "    for l in f:\n",
    "        if not l or l == '\\n':\n",
    "            # We have an empty line; if xT has data in it then decode it by working backwords                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "            if xT:\n",
    "                # Define the default values of v and w here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "                pi_max = float('-inf')\n",
    "                v_max = None\n",
    "                w_max = None\n",
    "\n",
    "                # Here we define the tag sequence of v and w\n",
    "                # pi(T, v, w) + np.log(get_transition(v, w, STOP, q)) is what we want to maximize\n",
    "                # We need v and w and from this we need to work back\n",
    "                v_tags = [START] if T == 1 else TAGS\n",
    "                w_tags = TAGS\n",
    "\n",
    "                for v in v_tags:\n",
    "                    for w in w_tags:\n",
    "                        FILL_IN\n",
    "                \n",
    "                # Set yT be the sequence [v_max, w_max] if T > 1 and [w_max] otherwise\n",
    "                yT = [v_max, w_max] if T > 1 else [w_max]\n",
    "\n",
    "                \"\"\"\n",
    "                Use backpointers to get the sequence we seek \n",
    "                This is the highest probability tag sequence (y1,..., yT)\n",
    "                Remember we just found v_max and w_max and we have \n",
    "                pi(T, v_max, w_max) = np.log(e(xT | w_max)) + \\max_{u}(q(w_max | v_max, y)*pi(T-1, u, v_max))\n",
    "                We need u, which should be u_max = bp[(T, v_max, w_max)]\n",
    "                We append this to yT to get [u_max, v_max, w_max]\n",
    "                We continue this process on until T = 1 (use a loop)\n",
    "                \"\"\"\n",
    "                for t in range(T-2, 0, -1):\n",
    "                    FILL_IN\n",
    "                \n",
    "                log_pT = []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "                assert(T == len(xT))\n",
    "                assert(len(yT) == len(xT))\n",
    "                \n",
    "                \"\"\"\n",
    "                We want to get the log probability of the sequence\n",
    "                For example, when we are at x1 this is\n",
    "                np.log(q(y1, START, START)) + np.log(e(x1|y1))\n",
    "                \"\"\"\n",
    "                for t in range(len(xT)):\n",
    "                    FILL_IN\n",
    "                for xt, yt, log_pt in zip(xT, yT, log_pT):\n",
    "                    g.write('{} {} {}\\n'.format(xt, yt, log_pt))\n",
    "                g.write('\\n')\n",
    "\n",
    "\n",
    "            # Reset all variables\n",
    "            # For the next sentence, we'll append words as we see them and compute these \n",
    "            pi = defaultdict(float)\n",
    "            bp = defaultdict(str)\n",
    "            pi[(0, START, START)] = 1.0\n",
    "            T = 0\n",
    "            xT = []\n",
    "        else:\n",
    "            # This is the forward step of Dynamic Programming, where we go from T-1 -> T\n",
    "            l = l.strip().split(' ')\n",
    "            #print(l)\n",
    "            T += 1\n",
    "            xt = l[-1]\n",
    "            xT.append(xt)\n",
    "\n",
    "            # q(w | v, u)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            # What can u be? Consider q(w | v, u) when T = 1 or T = 2 vs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "            u_tags = FILL_IN\n",
    "            # What can v be? Consider q(w | v, u) when T = 1 [Ovs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "            v_tags = FILL_IN\n",
    "            # What can w be? w can only be a true TAG, never START                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            w_tags = FILL_IN\n",
    "\n",
    "            \"\"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            For this we use the recursion below:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "            v, w in v_tags, w_tags while u is over u_tags\n",
    "\n",
    "            The probability recursion:\n",
    "            pi(t, v, w) = e(xt | w) max_{u}{q(w | v, u) * pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "\n",
    "            Becomes the log recursion:\n",
    "            pi(t, v, w) = log e(xt | w) + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "\n",
    "            We use logs below to make it easier and avoid overflow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            \"\"\"\n",
    "            for v in v_tags:\n",
    "                for w in w_tags:\n",
    "                    # e(x | w); this term is not in the max                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "                    e_temp = FILL_IN\n",
    "\n",
    "                    # pi(t, v, w) = log e(xt | w)  + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    pi_max = float('-inf')\n",
    "                    u_max = None\n",
    "\n",
    "                    # Do the max with respect to u                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "                    for u in u_tags:\n",
    "                        FILL_IN\n",
    "\n",
    "                    # The arg max of max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    bp[(T, v, w)] = FILL_IN\n",
    "\n",
    "                    # The log probability of ending in (v, w) at time T                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "                    pi[(T, v, w)] = FILL_IN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55db36",
   "metadata": {},
   "source": [
    "# Run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the number of lines in new_train.dat\n",
    "!wc -l ner_train.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "18e8a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python count_freqs.py ner_train.dat > ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5613140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 WORDTAG I-ORG EU\r\n",
      "1 WORDTAG O rejects\r\n",
      "84 WORDTAG I-MISC German\r\n",
      "30 WORDTAG O call\r\n",
      "3382 WORDTAG O to\r\n",
      "5 WORDTAG O boycott\r\n",
      "78 WORDTAG I-MISC British\r\n",
      "3 WORDTAG O lamb\r\n",
      "7362 WORDTAG O .\r\n",
      "31 WORDTAG I-PER Peter\r\n"
     ]
    }
   ],
   "source": [
    "!head ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1b86887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24968 ner.counts\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e29b28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # This does the flow of everything, you might want to comment out certain parts                                                                                                                                                                                                       \n",
    "q_counts, e_counts = get_q_e_counts('ner.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e3783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "06fdae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the new data and replace all rare words with _RARE_                                                                                                                                                                                                                             \n",
    "transform_data(e_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "04b0fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train_rare.dat\r\n"
     ]
    }
   ],
   "source": [
    "# Should be the same number of lines as above\n",
    "!wc -l ner_train_rare.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81cede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "21a32fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the count_freqs helper again to get the new counts                                                                                                                                                                                                                              \n",
    "# This requires a run outside of this                                                                                                                                                                                                                                                 \n",
    "!python count_freqs.py ner_train_rare.dat > ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c95796f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5959 ner_rare.counts\r\n"
     ]
    }
   ],
   "source": [
    "# Many words will get mapped to _RARE_, so it is fairly simple\n",
    "!wc -l ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ccc3f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rare counts for each word\n",
    "# These will allow us to get the new probabilities\n",
    "q_counts, e_counts = get_q_e_counts('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170175e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e3b57162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline model's performance                                                                                                                                                                                                                                                            \n",
    "baseline_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "53e3019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14043 NEs. Expected 5931 NEs; Correct: 3117.\r\n",
      "\r\n",
      "\t precision \trecall \t\tF1-Score\r\n",
      "Total:\t 0.221961\t0.525544\t0.312106\r\n",
      "PER:\t 0.435451\t0.231230\t0.302061\r\n",
      "ORG:\t 0.475936\t0.399103\t0.434146\r\n",
      "LOC:\t 0.147750\t0.870229\t0.252612\r\n",
      "MISC:\t 0.491689\t0.610206\t0.544574\r\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the baseline tagger\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0824ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96985d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/2_vxppc52znb82mg86nv4y000000gp/T/ipykernel_92997/3064444531.py:149: RuntimeWarning: divide by zero encountered in log\n",
      "  pi_temp = np.log(e_temp) + np.log(q_temp)  + pi[(T-1, u, v)]\n",
      "/var/folders/x8/2_vxppc52znb82mg86nv4y000000gp/T/ipykernel_92997/3064444531.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "  pi_temp = pi[(T, v, w)] + np.log(get_transition(v, w, STOP, q))\n"
     ]
    }
   ],
   "source": [
    "# Get HMM model's performance                                                                                                                                                                                                                                                                 \n",
    "hmm_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This evaluates the HMM tagger; performance should be about double that of the baseline\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.hmm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20305a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a0d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
