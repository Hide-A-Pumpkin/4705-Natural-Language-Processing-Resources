{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "a5460e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "WORDTAG = 'WORDTAG'\n",
    "GRAM1 = '1-GRAM'\n",
    "GRAM2 = '2-GRAM'\n",
    "GRAM3 = '3-GRAM'\n",
    "RARE = '_RARE_'\n",
    "RARE_THRESHOLD = 5\n",
    "# A I-LOC might be followed by B-LOC if a new location follow one immediately after another one                                                                                                              \n",
    "# There are 9 tags to consider                                                                                                                                                                               \n",
    "TAGS = [\n",
    "    'I-PER',\n",
    "    'I-ORG',\n",
    "    'I-LOC',\n",
    "    'I-MISC',\n",
    "    # 'B-PER',\n",
    "    'B-ORG',\n",
    "    'B-LOC',\n",
    "    'B-MISC',\n",
    "    'O'\n",
    "]\n",
    "# The start and stop symbols                                                                                                                                                                                 \n",
    "START = '*'\n",
    "STOP = 'STOP'\n",
    "\n",
    "FILL_IN = '_FILL_IN_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "9047be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_counts[(u, v, w)] = count(u, v, w)\n",
    "# q_counts[[u, v]] = count(u, v)\n",
    "# e_counts[(u, x)] = count(u, x)\n",
    "def get_q_e_counts(counts_file_name = 'ner.counts'):\n",
    "    f = open(counts_file_name)\n",
    "\n",
    "    q_counts = defaultdict(int)\n",
    "    e_counts = defaultdict(int)\n",
    "\n",
    "    for line in f:\n",
    "        elements = line.split(' ')\n",
    "        if elements[1]==WORDTAG:\n",
    "            e_counts[(elements[2], elements[3].strip())] = int(elements[0])\n",
    "            e_counts[elements[2]] +=int(elements[0])\n",
    "        elif elements[1]==GRAM1:\n",
    "            q_counts[elements[2].strip()] = elements[0]\n",
    "        elif elements[1] == GRAM2:\n",
    "            q_counts[(elements[2],elements[3].strip())] = int(elements[0])\n",
    "        elif elements[1]==GRAM3:\n",
    "            q_counts[(elements[2],elements[3],elements[4].strip())] = int(elements[0])\n",
    "    return q_counts, e_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "397c5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transforms the data into one involving the rare words                                                                                                                                                 \n",
    "# We then run the count_freqs.py utility to get the new counts across the corpus                                                                                                                             \n",
    "def transform_data(e_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "    Output:\n",
    "        Nothing; write to g\n",
    "    \"\"\"\n",
    "    f = open('ner_train.dat', 'r')\n",
    "    g = open('ner_train_rare.dat', 'w')\n",
    "\n",
    "    # why we need to calculate x_counts another time?\n",
    "    x_counts = defaultdict(int)\n",
    "    for key, val in e_counts.items():\n",
    "        if len(key)==2:\n",
    "            _,x = key\n",
    "            x_counts[x]+=val\n",
    "    \n",
    "    for line in f:\n",
    "        if len(line)<=1:\n",
    "           g.write(line) \n",
    "        else:\n",
    "            [word, type] = line.strip().split(' ')\n",
    "            if x_counts[word]>0 and x_counts[word] <5:\n",
    "                g.write('RARE '+type + '\\n')\n",
    "            else:\n",
    "                g.write(line)\n",
    "\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "2a0462e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities e(x_t | y_t)                                                                                                                                                                   \n",
    "def get_emission(y, x, e_counts, x_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y: A tag\n",
    "        x: A word\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "        x_counts: A dictionary with counts(x)\n",
    "    Output:\n",
    "        The probabilty e(x|y) or e(RARE|y) is x is rare\n",
    "        This is vartheta(x | y) in the lecture\n",
    "    \"\"\"\n",
    "    # If a rare word, return e(RARE | y)\n",
    "    if x_counts[x]<5:\n",
    "        return e_counts[(y, 'RARE')]/e_counts[y]\n",
    "    # Otherwise, return e(x | y)                                                                                                                                                                             \n",
    "    else:\n",
    "        return e_counts[(y,x)]/e_counts[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "36abd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not that for the baseline decoder we don't need Dynamic Programming\n",
    "# We have max_{y1, ..., YT} = max_{y1}(e(x1|y1))...max_{yT}(e(xT|yT))\n",
    "def baseline_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x, y, log(e(x|y))\" where y is the optimal tag for x\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.baseline_predictions', 'w')\n",
    "\n",
    "    _, e_counts = get_q_e_counts(counts_file_name)\n",
    "    \n",
    "    # Get the counts per word; this is used to get the rare words                                                                                                                                            \n",
    "    # What words need to be replaced with a rare word?\n",
    "    # Note that we do here is take all counts of (u, x) for all u to get the count for x\n",
    "    x_counts = defaultdict(int)\n",
    "    for key, val in e_counts.items():\n",
    "        if len(key)==2:\n",
    "            _,x = key\n",
    "            x_counts[x]+=val\n",
    "    \n",
    "\n",
    "    for l in f:\n",
    "        if not l or l == '\\n': # sentence finished.\n",
    "            g.write(' \\n')\n",
    "        else:\n",
    "            p_best = 0\n",
    "            y_best = 'O'\n",
    "            x = l.strip()\n",
    "            for type in TAGS:\n",
    "                if p_best < get_emission(type, x, e_counts, x_counts):\n",
    "                    p_best = get_emission(type, x, e_counts, x_counts)\n",
    "                    y_best = type\n",
    "            g.write('{} {} {}\\n'.format(x, y_best, np.log(p_best)))\n",
    "\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339a67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "e9014561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities p(y_t | y_{t-1}, y_{t-2})                                                                                                                                                      \n",
    "def get_transition(y1, y2, y3, q_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y1: The tag two away from the output tag\n",
    "        y2: The tag right before the output tag\n",
    "        y3: The output tag\n",
    "        q_counts: The counts we need for two or 3 tags beting seen together\n",
    "    Output:\n",
    "        q(w | v, u) which is theta(w | v, u) in the lecture\n",
    "    \"\"\"\n",
    "    if (y1, y2) not in q_counts.keys():\n",
    "        return 0\n",
    "    return q_counts[(y1,y2,y3)]/q_counts[(y1,y2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "c2856a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x_t, y_t, log(pi(t, y_{t-1}, y_t))\" where y_t is the optimal tag for x_t\n",
    "        Note that {y_t} is the optimal sequence here, computed by Dynamic Programming\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.hmm_predictions', 'w')\n",
    "\n",
    "    q_counts, e_counts = get_q_e_counts(counts_file_name)\n",
    "\n",
    "    # Get the counts per word; this is used to identify                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "    x_counts = defaultdict(int)\n",
    "    for key, val in e_counts.items():\n",
    "        if len(key)==2:\n",
    "            _,x = key\n",
    "            x_counts[x]+=val\n",
    "\n",
    "    # Can use log probabilities here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "    # Reset all variables                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "    pi = defaultdict(float)\n",
    "    bp = defaultdict(str)\n",
    "    pi[(0, START, START)] = 1.0\n",
    "    T = 0\n",
    "    xT = []\n",
    "    for l in f:\n",
    "        if not l or l == '\\n':\n",
    "            # We have an empty line; if xT has data in it then decode it by working backwords                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "            if xT:\n",
    "                # Define the default values of v and w here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "                pi_max = float('-inf')\n",
    "                v_max = None\n",
    "                w_max = None\n",
    "\n",
    "                # Here we define the tag sequence of v and w\n",
    "                # pi(T, v, w) + np.log(get_transition(v, w, STOP, q)) is what we want to maximize\n",
    "                # We need v and w and from this we need to work back\n",
    "                v_tags = [START] if T == 1 else TAGS\n",
    "                w_tags = TAGS\n",
    "\n",
    "                \n",
    "                for v in v_tags:\n",
    "                    for w in w_tags:\n",
    "                        value = np.log(get_transition(v, w, STOP, q_counts)) + pi[(T, v, w)]\n",
    "                        if value > pi_max:\n",
    "                            pi_max = value\n",
    "                            v_max = v\n",
    "                            w_max = w\n",
    "                        \n",
    "                \n",
    "                # Set yT be the sequence [v_max, w_max] if T > 1 and [w_max] otherwise\n",
    "                yT = [v_max, w_max] if T > 1 else [w_max]\n",
    "\n",
    "                \"\"\"\n",
    "                Use backpointers to get the sequence we seek \n",
    "                This is the highest probability tag sequence (y1,..., yT)\n",
    "                Remember we just found v_max and w_max and we have \n",
    "                pi(T, v_max, w_max) = np.log(e(xT | w_max)) + \\max_{u}(q(w_max | v_max, y)*pi(T-1, u, v_max))\n",
    "                We need u, which should be u_max = bp[(T, v_max, w_max)]\n",
    "                We append this to yT to get [u_max, v_max, w_max]\n",
    "                We continue this process on until T = 1 (use a loop)\n",
    "                \"\"\"\n",
    "                for t in range(T-2, 0, -1):\n",
    "                    u_max = bp[(t+2, yT[0], yT[1])] \n",
    "                    yT.insert(0, u_max)\n",
    "                \n",
    "                \n",
    "                log_pT = []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "                assert(T == len(xT))\n",
    "                assert(len(yT) == len(xT))\n",
    "                \"\"\"\n",
    "                We want to get the log probability of the sequence\n",
    "                For example, when we are at x1 this is\n",
    "                np.log(q(y1, START, START)) + np.log(e(x1|y1))\n",
    "                \"\"\"\n",
    "                for t in range(len(xT)):\n",
    "                    if t == 0:\n",
    "                        log_pT.append(np.log(get_transition(START, START, yT[t], q_counts)) + np.log(get_emission(yT[t],xT[t], e_counts, x_counts)))\n",
    "                    elif t==1:\n",
    "                        log_pT.append(np.log(get_transition(START, yT[t-1], yT[t], q_counts)) + np.log(get_emission(yT[t], xT[t], e_counts, x_counts)))\n",
    "                    else:\n",
    "                        log_pT.append(np.log(get_transition(yT[t-2], yT[t-1], yT[t], q_counts)) + np.log(get_emission(yT[t], xT[t], e_counts, x_counts)))\n",
    "                for xt, yt, log_pt in zip(xT, yT, log_pT):\n",
    "                    g.write('{} {} {}\\n'.format(xt, yt, log_pt))\n",
    "                g.write('\\n')\n",
    "\n",
    "\n",
    "            # Reset all variables\n",
    "            # For the next sentence, we'll append words as we see them and compute these \n",
    "            pi = defaultdict(float)\n",
    "            bp = defaultdict(str)\n",
    "            pi[(0, START, START)] = 1.0\n",
    "            T = 0\n",
    "            xT = []\n",
    "        else:\n",
    "            # This is the forward step of Dynamic Programming, where we go from T-1 -> T\n",
    "            l = l.strip().split(' ')\n",
    "            T += 1\n",
    "            xt = l[-1]\n",
    "            xT.append(xt)\n",
    "\n",
    "            # q(w | v, u)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            # What can u be? Consider q(w | v, u) when T = 1 or T = 2 vs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "            u_tags = [START] if T==1 or T == 2 else TAGS\n",
    "            \n",
    "            # What can v be? Consider q(w | v, u) when T = 1 [Ovs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "            v_tags = [START] if T == 1 else TAGS\n",
    "            # What can w be? w can only be a true TAG, never START                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            w_tags =  TAGS\n",
    "\n",
    "            \"\"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            For this we use the recursion below:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "            v, w in v_tags, w_tags while u is over u_tags\n",
    "\n",
    "            The probability recursion:\n",
    "            pi(t, v, w) = e(xt | w) max_{u}{q(w | v, u) * pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "\n",
    "            Becomes the log recursion:\n",
    "            pi(t, v, w) = log e(xt | w) + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "\n",
    "            We use logs below to make it easier and avoid overflow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            \"\"\"\n",
    "            for v in v_tags:\n",
    "                for w in w_tags:\n",
    "                    # e(x | w); this term is not in the max                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "                    e_temp = np.log(get_emission(w, xt, e_counts, x_counts))\n",
    "\n",
    "                    # pi(t, v, w) = log e(xt | w)  + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    pi_max = float('-inf')\n",
    "                    u_max = 'O'\n",
    "\n",
    "                    # Do the max with respect to u                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "                    for u in u_tags:\n",
    "                        transition_prob = np.log(get_transition(u, v, w,q_counts))\n",
    "                        pi_temp = transition_prob + pi[(T - 1, u, v)]\n",
    "                        if pi_temp > pi_max:\n",
    "                            pi_max = pi_temp\n",
    "                            u_max = u\n",
    "                    # The arg max of max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    bp[(T, v, w)] = u_max\n",
    "\n",
    "                    # The log probability of ending in (v, w) at time T                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "                    pi[(T, v, w)] = e_temp + pi_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "9889bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/1588869320.py:130: RuntimeWarning: divide by zero encountered in log\n",
      "  e_temp = np.log(get_emission(w, xt, e_counts, x_counts))\n",
      "/var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/1588869320.py:138: RuntimeWarning: divide by zero encountered in log\n",
      "  transition_prob = np.log(get_transition(u, v, w,q_counts))\n",
      "/var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/1588869320.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "  value = np.log(get_transition(v, w, STOP, q_counts)) + pi[(T, v, w)]\n"
     ]
    }
   ],
   "source": [
    "hmm_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55db36",
   "metadata": {},
   "source": [
    "# Run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "853e223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train.dat\n"
     ]
    }
   ],
   "source": [
    "# This gets the number of lines in new_train.dat\n",
    "!wc -l ner_train.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "18e8a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python count_freqs.py ner_train.dat > ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "5613140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 WORDTAG O mind\n",
      "5 WORDTAG O 416\n",
      "1 WORDTAG I-PER Solano\n",
      "1 WORDTAG O Sep.03\n",
      "2 WORDTAG I-MISC Carnival\n",
      "2 WORDTAG I-PER O.J.\n",
      "31 WORDTAG I-PER Peter\n",
      "1 WORDTAG O one-third\n",
      "1 WORDTAG O STEP\n",
      "1 WORDTAG I-LOC Western\n"
     ]
    }
   ],
   "source": [
    "!head ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "1b86887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24968 ner.counts\n"
     ]
    }
   ],
   "source": [
    "!wc -l ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "e29b28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # This does the flow of everything, you might want to comment out certain parts                                                                                                                                                                                                       \n",
    "q_counts, e_counts = get_q_e_counts('ner.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e3783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "06fdae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the new data and replace all rare words with _RARE_                                                                                                                                                                                                                             \n",
    "transform_data(e_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "04b0fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train_rare.dat\n"
     ]
    }
   ],
   "source": [
    "# Should be the same number of lines as above\n",
    "!wc -l ner_train_rare.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81cede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "21a32fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the count_freqs helper again to get the new counts                                                                                                                                                                                                                              \n",
    "# This requires a run outside of this                                                                                                                                                                                                                                                 \n",
    "!python count_freqs.py ner_train_rare.dat > ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c95796f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5959 ner_rare.counts\n"
     ]
    }
   ],
   "source": [
    "# Many words will get mapped to _RARE_, so it is fairly simple\n",
    "!wc -l ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "b5c6dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5959 ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "ccc3f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rare counts for each word\n",
    "# These will allow us to get the new probabilities\n",
    "q_counts, e_counts = get_q_e_counts('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170175e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "e3b57162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline model's performance                                                                                                                                                                                                                                                            \n",
    "baseline_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "53e3019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14043 NEs. Expected 5931 NEs; Correct: 3117.\n",
      "\n",
      "\t precision \trecall \t\tF1-Score\n",
      "Total:\t 0.221961\t0.525544\t0.312106\n",
      "PER:\t 0.435451\t0.231230\t0.302061\n",
      "ORG:\t 0.475936\t0.399103\t0.434146\n",
      "LOC:\t 0.147750\t0.870229\t0.252612\n",
      "MISC:\t 0.491689\t0.610206\t0.544574\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the baseline tagger\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "d0824ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# /var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/3215609725.py:40: RuntimeWarning: divide by zero encountered in log\n",
    "#   g.write('{} {} {}\\n'.format(x, y_best, np.log(p_best)))\n",
    "#   217662 ner_train.dat\n",
    "# 24 WORDTAG I-ORG EU\n",
    "# 1 WORDTAG O rejects\n",
    "# 84 WORDTAG I-MISC German\n",
    "# 30 WORDTAG O call\n",
    "# 3382 WORDTAG O to\n",
    "# 5 WORDTAG O boycott\n",
    "# 78 WORDTAG I-MISC British\n",
    "# 3 WORDTAG O lamb\n",
    "# 7362 WORDTAG O .\n",
    "# 31 WORDTAG I-PER Peter\n",
    "#    24968 ner.counts\n",
    "#   217662 ner_train_rare.dat\n",
    "#     5959 ner_rare.counts\n",
    "# Found 14043 NEs. Expected 5931 NEs; Correct: 3117.\n",
    "\n",
    "# \t precision \trecall \t\tF1-Score\n",
    "# Total:\t 0.221961\t0.525544\t0.312106\n",
    "# PER:\t 0.435451\t0.231230\t0.302061\n",
    "# ORG:\t 0.475936\t0.399103\t0.434146\n",
    "# LOC:\t 0.147750\t0.870229\t0.252612\n",
    "# MISC:\t 0.491689\t0.610206\t0.544574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "96985d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/1588869320.py:130: RuntimeWarning: divide by zero encountered in log\n",
      "  e_temp = np.log(get_emission(w, xt, e_counts, x_counts))\n",
      "/var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/1588869320.py:138: RuntimeWarning: divide by zero encountered in log\n",
      "  transition_prob = np.log(get_transition(u, v, w,q_counts))\n",
      "/var/folders/gp/vbs7gg5x7txdvt7z40ms8wx80000gn/T/ipykernel_12288/1588869320.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "  value = np.log(get_transition(v, w, STOP, q_counts)) + pi[(T, v, w)]\n"
     ]
    }
   ],
   "source": [
    "# Get HMM model's performance                                                                                                                                                                                                                                                                 \n",
    "hmm_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "8323bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4704 NEs. Expected 5931 NEs; Correct: 3647.\n",
      "\n",
      "\t precision \trecall \t\tF1-Score\n",
      "Total:\t 0.775298\t0.614905\t0.685849\n",
      "PER:\t 0.762535\t0.595756\t0.668907\n",
      "ORG:\t 0.611855\t0.478326\t0.536913\n",
      "LOC:\t 0.876458\t0.696292\t0.776056\n",
      "MISC:\t 0.830065\t0.689468\t0.753262\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the HMM tagger; performance should be about double that of the baseline\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.hmm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20305a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a0d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
