{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"080d50fc","outputId":"271fc331-8ed3-4c3a-e4a1-de9ddab8c8e1","executionInfo":{"status":"ok","timestamp":1701293721358,"user_tz":300,"elapsed":15383,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting portalocker\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-2.8.2\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.0\n"]}],"source":["!pip install portalocker\n","!pip install torchmetrics"],"id":"080d50fc"},{"cell_type":"code","execution_count":2,"metadata":{"id":"B9XxyEQVWrO6","executionInfo":{"status":"ok","timestamp":1701293728147,"user_tz":300,"elapsed":6829,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":["import argparse\n","import logging\n","import time\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","from torchtext.data.utils import get_tokenizer, ngrams_iterator\n","from torchtext.datasets import DATASETS\n","from torchtext.prototype.transforms import load_sp_model, PRETRAINED_SP_MODEL, SentencePieceTokenizer\n","from torchtext.utils import download_from_url\n","from torchtext.vocab import build_vocab_from_iterator\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","from torchtext.vocab import GloVe\n","from tqdm import tqdm\n","\n","torch.autograd.set_detect_anomaly(True)\n","\n","FILL = '_FILL_'"],"id":"B9XxyEQVWrO6"},{"cell_type":"markdown","metadata":{"id":"66eb271d"},"source":["### Information\n","- torchtext repo: https://github.com/pytorch/text/tree/main/torchtext\n","- torchtext documentation: https://pytorch.org/text/stable/index.html"],"id":"66eb271d"},{"cell_type":"code","execution_count":2,"metadata":{"id":"8c949153","executionInfo":{"status":"ok","timestamp":1701293728148,"user_tz":300,"elapsed":41,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":[],"id":"8c949153"},{"cell_type":"markdown","metadata":{"id":"12d93d22"},"source":["### Constants"],"id":"12d93d22"},{"cell_type":"code","execution_count":3,"metadata":{"id":"329c056d","executionInfo":{"status":"ok","timestamp":1701293728149,"user_tz":300,"elapsed":39,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":["DATASET = \"AG_NEWS\"\n","DATA_DIR = \".data\"\n","DEVICE = \"cpu\"\n","EMBED_DIM = 300\n","LR = 1.0\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 5\n","PADDING_VALUE = 0\n","PADDING_IDX = PADDING_VALUE"],"id":"329c056d"},{"cell_type":"code","execution_count":3,"metadata":{"id":"ffada8d0","executionInfo":{"status":"ok","timestamp":1701293728149,"user_tz":300,"elapsed":38,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":[],"id":"ffada8d0"},{"cell_type":"markdown","metadata":{"id":"1a61aede"},"source":["### Get the tokenizer\n","- Use the WordLevel tokenizer.\n"],"id":"1a61aede"},{"cell_type":"code","execution_count":4,"metadata":{"id":"93e3b7cb","executionInfo":{"status":"ok","timestamp":1701293728270,"user_tz":300,"elapsed":14,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":["# Get basic tokenizer\n","basic_english_tokenizer = get_tokenizer(\"basic_english\")"],"id":"93e3b7cb"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa4b78e4","outputId":"644cb434-31f7-42ac-a1a3-259c5d7286db","executionInfo":{"status":"ok","timestamp":1701293728270,"user_tz":300,"elapsed":12,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['this', 'is', 'some', 'text', '.', '.', '.']"]},"metadata":{},"execution_count":5}],"source":["basic_english_tokenizer(\"This is some text ...\")"],"id":"aa4b78e4"},{"cell_type":"code","execution_count":6,"metadata":{"id":"505cf5ec","executionInfo":{"status":"ok","timestamp":1701293728271,"user_tz":300,"elapsed":10,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":["# Needed later; set this to the tokenizer above\n","TOKENIZER = basic_english_tokenizer"],"id":"505cf5ec"},{"cell_type":"markdown","metadata":{"id":"64096cd8"},"source":["### Get the data and get the vocabulary"],"id":"64096cd8"},{"cell_type":"code","execution_count":7,"metadata":{"id":"ce4a0578","executionInfo":{"status":"ok","timestamp":1701293728271,"user_tz":300,"elapsed":8,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":["def yield_tokens(data_iter):\n","    for _, text in data_iter:\n","        yield TOKENIZER(text)"],"id":"ce4a0578"},{"cell_type":"code","execution_count":8,"metadata":{"id":"f48f23ab","executionInfo":{"status":"ok","timestamp":1701293739347,"user_tz":300,"elapsed":11083,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":["train_iter = DATASETS[DATASET](root=DATA_DIR, split=\"train\")\n","VOCAB = build_vocab_from_iterator(yield_tokens(train_iter), specials=('<pad>', '<unk>'))\n","\n","# Make the default index the same as that of the unk_token.\n","VOCAB.set_default_index(VOCAB['<unk>'])"],"id":"f48f23ab"},{"cell_type":"code","execution_count":8,"metadata":{"id":"552e7295","executionInfo":{"status":"ok","timestamp":1701293739349,"user_tz":300,"elapsed":50,"user":{"displayName":"Yunqing Qiu","userId":"02114787863698398374"}}},"outputs":[],"source":[],"id":"552e7295"},{"cell_type":"markdown","metadata":{"id":"31ce9367"},"source":["### Get GLOVE embeddings"],"id":"31ce9367"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a43f0226","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b25a6b8-4090-4b60-97be-e8a4a3d96b8f"},"outputs":[{"output_type":"stream","name":"stderr","text":[".vector_cache/glove.840B.300d.zip: 2.18GB [06:50, 5.30MB/s]                            \n"]}],"source":["# Get the GloVe embeddings; this will be slow\n","GLOVE = GloVe()"],"id":"a43f0226"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6302f433"},"outputs":[],"source":["len(GLOVE), GLOVE.vectors.shape"],"id":"6302f433"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1ba2b54"},"outputs":[],"source":[],"id":"c1ba2b54"},{"cell_type":"markdown","metadata":{"id":"200b05fc"},"source":["### Helper functions"],"id":"200b05fc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"16ca1ef5"},"outputs":[],"source":["def text_pipeline(text):\n","    return VOCAB(TOKENIZER(text))\n","\n","def label_pipeline(label):\n","    return int(label) - 1"],"id":"16ca1ef5"},{"cell_type":"markdown","metadata":{"id":"67ef6734"},"source":["Nice link on collate_fn and DataLoader in PyTorch: https://python.plainenglish.io/understanding-collate-fn-in-pytorch-f9d1742647d3"],"id":"67ef6734"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff479986"},"outputs":[],"source":["# As before, loop through the batch and transform into tensors\n","def collate_batch(batch):\n","    label_list, text_list = [], []\n","    for (_label, _text) in batch:\n","        # Get the label from {1, 2, 3, 4} to {0, 1, 2, 3}\n","        label_list.append(label_pipeline(_label))\n","\n","        # Return a list of ints\n","        processed_text = torch.tensor(text_pipeline(_text))\n","        # Append to text_list\n","        text_list.append(processed_text.clone().detach())\n","\n","    # Pad and make into tensors as needed\n","    label_list = torch.tensor(label_list)\n","    text_list = pad_sequence(text_list, batch_first=True)\n","\n","    return label_list.to(DEVICE), text_list.to(DEVICE)"],"id":"ff479986"},{"cell_type":"code","execution_count":null,"metadata":{"id":"aa668c1e"},"outputs":[],"source":[],"id":"aa668c1e"},{"cell_type":"markdown","metadata":{"id":"c7fcf425"},"source":["### Get the data"],"id":"c7fcf425"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e617ddce"},"outputs":[],"source":["train_iter = DATASETS[DATASET](root=DATA_DIR, split=\"train\")\n","num_class = len(set([label for (label, _) in train_iter]))\n","# What are the classes?\n","print(f\"The number of classes is {num_class} ...\")"],"id":"e617ddce"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7770ac24"},"outputs":[],"source":[],"id":"7770ac24"},{"cell_type":"markdown","metadata":{"id":"5aa8a40d"},"source":["### Set up the model"],"id":"5aa8a40d"},{"cell_type":"markdown","metadata":{"id":"8abf2ede"},"source":["Good reference on this type of model\n","- CNN for Sentence Classification: https://arxiv.org/pdf/1408.5882.pdf\n","\n","You can build CNN models with either CNN1d or CNN2d."],"id":"8abf2ede"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dc51c359"},"outputs":[],"source":["class CNN1dTextClassificationModel(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        num_class,\n","        embed_dim = 300,\n","        use_pretrained = True,\n","        fine_tune_embeddings = True,\n","        debug = True\n","    ):\n","\n","        super(CNN1dTextClassificationModel, self).__init__()\n","\n","        self.embedding = nn.Embedding(\n","            vocab_size,\n","            embed_dim,\n","            padding_idx=PADDING_IDX\n","        )\n","\n","        if use_pretrained:\n","            # Set the embeddings to not requiring gradients since we'll try and modify\n","            self.embedding.weight.requires_grad = False\n","            for i in range(vocab_size):\n","                # Get the token for the index i\n","                token = VOCAB.lookup_token(i)\n","                # Modify the embedding for index i by the embedding for that token\n","                # Do this only if token is in the stoi dictionary for GLOVE\n","                if token in GLOVE.stoi:\n","                    self.embedding.weight[i, :] = GLOVE.get_vecs_by_tokens(token)\n","\n","            self.embedding.weight.requires_grad = True\n","        else:\n","            # Otherwise, initialize the weights as specified below\n","            self.init_weights()\n","\n","        # If weights do not get changed, turn off gradients for the GloVe embeddings\n","        if not fine_tune_embeddings:\n","            self.embedding.weight.requires_grad = False\n","\n","        # Define a Conv1d layer that collapses all the channels and does not collapse the time dimension\n","        self.cnn1 = nn.Conv1d(embed_dim,1,1)\n","\n","        # Define 3 Conv1d layers each having 1 filter and kernel sizes 2, 3 and 4\n","        self.cnn2 = nn.Conv1d(embed_dim,1,2)\n","        self.cnn3 = nn.Conv1d(embed_dim,1,3)\n","        self.cnn4 = nn.Conv1d(embed_dim,1,4)\n","\n","        # A linear map from some dimensions to num_class (you need to figure it out)\n","        self.fc = nn.Linear(3, num_class)\n","\n","        self.debug = debug\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        # Initialize the embedding weight matrix to uniform between the [-0.5, 0.5]\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        # Initialize the weight matrix of fc to uniform between the [-0.5, 0.5]\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        # Initialize the bias for fc to zero\n","        self.fc.bias.data.zero_()\n","\n","    # B = batch_size, L = sequence length, D = vector dimension\n","    def forward(self, text):\n","\n","        # B X L X D\n","        # Get the embeddings for the text passed in\n","        embedded = self.embedding(text)\n","\n","        if self.debug:\n","            print('embedding', embedded.shape)\n","\n","        # B X D X L\n","        # Transpose the embedding above as needed\n","        # embedded = torch.transpose(embedded,0,1)\n","        embedded = embedded.permute(0, 2, 1)\n","\n","        # B X 1 X L\n","        # Pass through cnn1\n","        cnn1 = self.cnn1(embedded)\n","        if self.debug:\n","            print('cnn1', cnn1.shape)\n","\n","        # B X 1\n","        # Take Max pooling over time\n","        cnn1 = F.max_pool1d(cnn1, cnn1.size(2)).squeeze(dim=2)\n","        if self.debug:\n","          print('cnn1 after max pool', cnn1.shape)\n","\n","        # B X 1 X L - 1\n","        # Pass through cnn2 and add a RELU\n","        cnn2 = F.relu(self.cnn2(embedded))\n","        if self.debug:\n","            print('cnn2', cnn2.shape)\n","\n","        # B X 1 X L - 2\n","        # Pass through cnn3 and add a RELU\n","        cnn3 = F.relu(self.cnn3(embedded))\n","        if self.debug:\n","            print('cnn3', cnn3.shape)\n","\n","        # B X 1 X L - 3\n","        # Pass through cnn4 and add a RELU\n","        cnn4 = F.relu(self.cnn4(embedded))\n","        if self.debug:\n","            print('cnn4', cnn4.shape)\n","\n","        # B X 1 in all cases\n","        # Apply max pooling to each of cnn2, cnn3 and cnn4\n","        cnn2 = F.max_pool1d(cnn2, cnn2.size(2)).squeeze(dim=2)\n","        cnn3 = F.max_pool1d(cnn3, cnn3.size(2)).squeeze(dim=2)\n","        cnn4 = F.max_pool1d(cnn4, cnn4.size(2)).squeeze(dim=2)\n","\n","        # B X 1 in all cases\n","        # Apply max pooling over time\n","        if self.debug:\n","            print('cnn2 after max', cnn2.shape)\n","\n","        # Add to each cnn2, 3, 4 a skip connection to cnn1 and average the results\n","        cnn2 = (cnn2 + cnn1) / 2\n","        cnn3 = (cnn3 + cnn1) / 2\n","        cnn4 = (cnn4 + cnn1) / 2\n","        if self.debug:\n","            print('cnn2 after skip connection', cnn2.shape)\n","\n","        # B X 3\n","        # Concatenate the above\n","        cnn_concat = torch.cat((cnn2, cnn3, cnn4), 1)\n","        if self.debug:\n","            print('cnn concat', cnn_concat.shape)\n","            # Set the debug to False after the first forward pass\n","            self.debug = False\n","\n","        # Pass through an appropriate Linear layer to get the right dimensions needed\n","        out = self.fc(cnn_concat)\n","\n","        return out"],"id":"dc51c359"},{"cell_type":"code","execution_count":null,"metadata":{"id":"25775647"},"outputs":[],"source":[],"id":"25775647"},{"cell_type":"markdown","metadata":{"id":"3b3c6ed5"},"source":["### Set up the model"],"id":"3b3c6ed5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cef585f4"},"outputs":[],"source":["# If this is True, we will initialize the Embedding layer with GLOVE\n","USE_PRETRANED = True,\n","\n","# If this is True, we will allow for gradient updates on the nn.Embedding layer\n","FINE_TUNE_EMBEDDINGS = True\n","\n","# Set the loss appropriately\n","criterion = nn.CrossEntropyLoss()\n","\n","model = CNN1dTextClassificationModel(\n","    len(VOCAB),\n","    num_class,\n","    EMBED_DIM,\n","    use_pretrained=USE_PRETRANED,\n","    fine_tune_embeddings=FINE_TUNE_EMBEDDINGS\n",").to(DEVICE)\n","\n","# Set the optimizer to SGD\n","# Add an L2 regularizer of 0.00001\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR, weight_decay=0.00001)\n","\n","# Set the scheduler to StepLR with gamma=0.1 and step_size = 1.0\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"],"id":"cef585f4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8a642bf"},"outputs":[],"source":[],"id":"f8a642bf"},{"cell_type":"markdown","metadata":{"id":"26266d8a"},"source":["### Set up the data"],"id":"26266d8a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c0aebb5"},"outputs":[],"source":["train_iter, test_iter = DATASETS[DATASET]()\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","\n","num_train = int(len(train_dataset) * 0.95)\n","split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n","\n","train_dataloader = DataLoader(\n","    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","valid_dataloader =  DataLoader(\n","    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","test_dataloader = DataLoader(\n","    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")"],"id":"9c0aebb5"},{"cell_type":"markdown","metadata":{"id":"86476e2a"},"source":["### Train the model"],"id":"86476e2a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"24950481"},"outputs":[],"source":["def train(dataloader, model, optimizer, criterion, epoch):\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    total_loss, total_batches = 0.0, 0\n","    total_zero_gradients_percentage = []\n","    log_interval = 10\n","\n","    for idx, (label, text) in tqdm(enumerate(dataloader)):\n","        # Set gradients to zero\n","        optimizer.zero_grad()\n","\n","        # Get the predictions\n","        predicted_label = model(text)\n","\n","        # Get the loss\n","        loss = criterion(predicted_label, label)\n","\n","        # Do back propagation and get the gradients\n","        loss.backward()\n","\n","        # Get the loss per batch and the number of batches\n","        with torch.no_grad():\n","            total_loss += loss\n","            total_batches += 1\n","\n","\n","        # Loop through all the parameters\n","        # Specifically, for this batch, get the percentage of zero gradients across all parameters\n","        # Append this to the list above which will print out the total every 10 batches\n","        total_nonzero_gradients = 0.0\n","        total_param_count = 0.0\n","\n","        for parameter in model.parameters():\n","            if parameter.grad is not None:\n","                total_param_count += parameter.numel()\n","                total_nonzero_gradients += torch.count_nonzero(parameter.grad).item()\n","\n","        # Append to total_zero_gradients_percentage\n","        zero_gradient_percentage = (1 - total_nonzero_gradients / total_param_count) * 100\n","        total_zero_gradients_percentage.append(zero_gradient_percentage)\n","\n","\n","        # Clip the gradient at ?? Should we use 10.0 or 0.1 with the learning rate we picked and the default notebook setting?\n","        # Use the above loop to help you figure this out\n","        nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","\n","        # Do an optimization step\n","        optimizer.step()\n","\n","        # Get the accuracy\n","        total_acc += (predicted_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","\n","        # Log results\n","        if idx % log_interval == 0 and idx > 0:\n","            print(\n","                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n","                \"| accuracy {:8.3f} \"\n","                \"| loss {:8.3f} \"\n","                \"| zero gradients percentage {:8.3f}\".format(\n","                    epoch, idx,\n","                    len(dataloader),\n","                    total_acc / total_count,\n","                    total_loss / total_batches,\n","                    torch.tensor(total_zero_gradients_percentage).mean().item()\n","                    )\n","            )\n","            # Reset variables as needed\n","            total_acc, total_count = 0, 0\n","            total_loss, total_batches = 0.0, 0\n","            total_zero_gradients = []"],"id":"24950481"},{"cell_type":"code","execution_count":null,"metadata":{"id":"39a702be"},"outputs":[],"source":["def evaluate(dataloader, model, criterion):\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        for idx, (label, text) in enumerate(dataloader):\n","            predited_label = model(text)\n","            loss = criterion(input=predited_label, target=label)\n","            total_acc += (predited_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","            total_loss += loss\n","    return total_acc / total_count, total_loss / total_count"],"id":"39a702be"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9e02c09"},"outputs":[],"source":["for epoch in range(1, NUM_EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader, model, optimizer, criterion, epoch)\n","    accu_val, loss_val = evaluate(valid_dataloader, model, criterion)\n","    scheduler.step()\n","    print(\"-\" * 59)\n","    print(\n","        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n","        \"valid accuracy {:8.3f} \".format(\n","            epoch,\n","            time.time() - epoch_start_time,\n","            accu_val,\n","            loss_val\n","            )\n","    )\n","    print(\"-\" * 59)\n","\n","print(\"Checking the results of test dataset.\")\n","accu_test, loss_test = evaluate(test_dataloader, model, criterion)\n","print(\"test accuracy {:8.3f}\".format(accu_test))\n","print(\"test loss {:8.3f}\".format(loss_test))"],"id":"a9e02c09"}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}